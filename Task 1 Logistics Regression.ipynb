{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "53c5ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9  ...  4990  4991  4992  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "\n",
      "   4993  4994  4995  4996  4997  4998  4999  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read csv files\n",
    "train_df = pd.read_csv('./dataset/train_tfidf_features.csv')\n",
    "test_df = pd.read_csv('./dataset/test_tfidf_features.csv')\n",
    "\n",
    "X_train = train_df.drop(['id', 'label'], axis=1) # Features\n",
    "y_train = train_df['label'] # Labels\n",
    "X_test = test_df.drop(['id'], axis=1) # Test Features\n",
    "test_ids = test_df['id']\n",
    "\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf3befdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "959270a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_hat):\n",
    "    return -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "49ea44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(X, y, y_hat):\n",
    "    m = X.shape[0]\n",
    "    dw = (1/m)*np.dot(X.T, (y_hat - y))\n",
    "    db = (1/m)*np.sum((y_hat - y))\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f763ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, bs, epochs, lr):\n",
    "    m, n = X.shape\n",
    "    w = np.zeros((n, 1))\n",
    "    b = 0\n",
    "    y = y.values.reshape(m,1)\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range((m - 1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = X[start_i:end_i]\n",
    "            yb = y[start_i:end_i]\n",
    "            \n",
    "            # Calculate hypothesis\n",
    "            y_hat = sigmoid(np.dot(xb, w) + b)\n",
    "            \n",
    "            # Getting gradients of loss\n",
    "            dw, db = gradients(xb, yb, y_hat)\n",
    "            \n",
    "            # Update parameters\n",
    "            w -= lr*dw\n",
    "            b -= lr*db\n",
    "            \n",
    "        # Calculating loss and appending to list\n",
    "        l = loss(y, sigmoid(np.dot(X, w) + b))\n",
    "        losses.append(l)\n",
    "        \n",
    "    return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09631d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    preds = sigmoid(np.dot(X, w) + b)\n",
    "    pred_class = [1 if i > 0.5 else 0 for i in preds]\n",
    "    return np.array(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72d5f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def f1_score(y_true, y_pred, class_label):\n",
    "    tp = np.sum((y_true == class_label) & (y_pred == class_label))\n",
    "    fp = np.sum((y_true != class_label) & (y_pred == class_label))\n",
    "    fn = np.sum((y_true == class_label) & (y_pred != class_label))\n",
    "    \n",
    "    if tp + 0.5 * (fp + fn) == 0:\n",
    "        return 0\n",
    "    \n",
    "    f1 = tp / (tp + 0.5 * (fp + fn))\n",
    "    return f1\n",
    "\n",
    "def macro_f1_score(y_true, y_pred):\n",
    "    f1_hateful = f1_score(y_true, y_pred, class_label=1)\n",
    "    f1_non_hateful = f1_score(y_true, y_pred, class_label=0)\n",
    "    return (f1_hateful + f1_non_hateful) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5ea86a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.6222067039106145\n",
      "F1 Score for Hateful (class 1): 0.026394721055788842\n",
      "F1 Score for Non-Hateful (class 0): 0.7656317689530686\n",
      "Macro F1 Score: 0.39601324500442875\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "w, b, l = train(X_train, y_train, bs=64, epochs=100, lr=0.01)\n",
    "\n",
    "# Prediction on training set\n",
    "y_train_pred = predict(X_train, w, b)\n",
    "\n",
    "# Save predictions to CSV for the test set\n",
    "y_test_pred = predict(X_test, w, b)\n",
    "predictions_df = pd.DataFrame({'id': test_df['id'], 'label': y_test_pred})\n",
    "predictions_df.to_csv('LogRed_Prediction.csv', index=False)\n",
    "\n",
    "# Evaluate on training set\n",
    "print(\"Training set accuracy:\", accuracy(y_train, y_train_pred))\n",
    "print(\"F1 Score for Hateful (class 1):\", f1_score(y_train, y_train_pred, 1))\n",
    "print(\"F1 Score for Non-Hateful (class 0):\", f1_score(y_train, y_train_pred, 0))\n",
    "print(\"Macro F1 Score:\", macro_f1_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168e6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
